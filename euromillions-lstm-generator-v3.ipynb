{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "labels = [\"Lucky Star 1\", \"Lucky Star 2\", \"Ball 1\", \"Ball 2\", \"Ball 3\", \"Ball 4\", \"Ball 5\"]\n",
    "column_labels = [\"Lucky Star 1\", \"Lucky Star 2\", \"Ball 1\", \"Ball 2\", \"Ball 3\", \"Ball 4\", \"Ball 5\", \"Ball Delta\", \"Ball Y Delta\", \"LS Delta\",\n",
    "    \"Ball 1 Repeat Last 5\", \"Ball 2 Repeat Last 5\", \"Ball 3 Repeat Last 5\", \"Ball 4 Repeat Last 5\", \"Ball 5 Repeat Last 5\", \"Lucky Star 1 Repeat Last 5\", \"Lucky Star 2 Repeat Last 5\",\n",
    "    \"Ball 1 Repeat Last 10\", \"Ball 2 Repeat Last 10\", \"Ball 3 Repeat Last 10\", \"Ball 4 Repeat Last 10\", \"Ball 5 Repeat Last 10\", \"Lucky Star 1 Repeat Last 10\", \"Lucky Star 2 Repeat Last 10\",\n",
    "    \"Ball 1 Repeat Last 20\", \"Ball 2 Repeat Last 20\", \"Ball 3 Repeat Last 20\", \"Ball 4 Repeat Last 20\", \"Ball 5 Repeat Last 20\", \"Lucky Star 1 Repeat Last 20\", \"Lucky Star 2 Repeat Last 20\"\n",
    "]\n",
    "column_indices = {name: i for i, name in enumerate(column_labels)}\n",
    "\n",
    "\n",
    "df = pd.read_excel(\"lottery-numbers-tracker.xlsx\", sheet_name=\"EuroMillions\", header=0)\n",
    "\n",
    "df[column_labels].to_csv(\"euromillions-dataset.csv\", index=None)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T01:46:39.893996Z",
     "start_time": "2025-01-12T01:46:37.338605Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('euromillions-dataset.csv')\n",
    "df[\"Ball Y Delta 2\"] = df[\"Ball Y Delta\"]\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T01:46:41.418189Z",
     "start_time": "2025-01-12T01:46:41.398934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     Lucky Star 1  Lucky Star 2  Ball 1  Ball 2  Ball 3  Ball 4  Ball 5  \\\n",
       "0               6             7      12      27      36      37      42   \n",
       "1               4            12      20      33      35      41      47   \n",
       "2               1             9       3      19      29      35      37   \n",
       "3               8            12      19      24      26      28      33   \n",
       "4               4             8      12      22      27      33      45   \n",
       "..            ...           ...     ...     ...     ...     ...     ...   \n",
       "299             6             9       1      19      36      38      49   \n",
       "300             9            10      10      25      29      34      45   \n",
       "301             2             4       6      16      18      39      47   \n",
       "302             7            12       5      14      35      36      39   \n",
       "303             2             5       3      12      19      24      30   \n",
       "\n",
       "     Ball Delta  Ball Y Delta  LS Delta  ...  Lucky Star 1 Repeat Last 10  \\\n",
       "0      4.555217      2.383275       1.0  ...                          2.0   \n",
       "1      3.913119      5.126402       8.0  ...                          2.0   \n",
       "2      4.974937      3.768289       8.0  ...                          0.0   \n",
       "3      1.903943      2.986637       4.0  ...                          2.0   \n",
       "4      4.366062      5.803447       4.0  ...                          1.0   \n",
       "..          ...           ...       ...  ...                          ...   \n",
       "299    6.791539      2.814249       3.0  ...                          0.0   \n",
       "300    4.918079      3.143247       1.0  ...                          0.0   \n",
       "301    6.169481      3.831449       2.0  ...                          1.0   \n",
       "302         NaN           NaN       NaN  ...                          NaN   \n",
       "303         NaN           NaN       NaN  ...                          NaN   \n",
       "\n",
       "     Lucky Star 2 Repeat Last 10  Ball 1 Repeat Last 20  \\\n",
       "0                            1.0                    3.0   \n",
       "1                            2.0                    1.0   \n",
       "2                            3.0                    1.0   \n",
       "3                            2.0                    2.0   \n",
       "4                            2.0                    2.0   \n",
       "..                           ...                    ...   \n",
       "299                          1.0                    0.0   \n",
       "300                          0.0                    0.0   \n",
       "301                          0.0                    0.0   \n",
       "302                          NaN                    NaN   \n",
       "303                          NaN                    NaN   \n",
       "\n",
       "     Ball 2 Repeat Last 20  Ball 3 Repeat Last 20  Ball 4 Repeat Last 20  \\\n",
       "0                      1.0                    0.0                    2.0   \n",
       "1                      5.0                    2.0                    0.0   \n",
       "2                      3.0                    4.0                    1.0   \n",
       "3                      2.0                    0.0                    1.0   \n",
       "4                      1.0                    1.0                    3.0   \n",
       "..                     ...                    ...                    ...   \n",
       "299                    1.0                    1.0                    0.0   \n",
       "300                    0.0                    0.0                    0.0   \n",
       "301                    0.0                    0.0                    1.0   \n",
       "302                    NaN                    NaN                    NaN   \n",
       "303                    NaN                    NaN                    NaN   \n",
       "\n",
       "     Ball 5 Repeat Last 20  Lucky Star 1 Repeat Last 20  \\\n",
       "0                      2.0                          5.0   \n",
       "1                      3.0                          2.0   \n",
       "2                      1.0                          2.0   \n",
       "3                      4.0                          4.0   \n",
       "4                      2.0                          1.0   \n",
       "..                     ...                          ...   \n",
       "299                    0.0                          0.0   \n",
       "300                    0.0                          0.0   \n",
       "301                    0.0                          1.0   \n",
       "302                    NaN                          NaN   \n",
       "303                    NaN                          NaN   \n",
       "\n",
       "     Lucky Star 2 Repeat Last 20  Ball Y Delta 2  \n",
       "0                            3.0        2.383275  \n",
       "1                            5.0        5.126402  \n",
       "2                            6.0        3.768289  \n",
       "3                            4.0        2.986637  \n",
       "4                            3.0        5.803447  \n",
       "..                           ...             ...  \n",
       "299                          1.0        2.814249  \n",
       "300                          0.0        3.143247  \n",
       "301                          0.0        3.831449  \n",
       "302                          NaN             NaN  \n",
       "303                          NaN             NaN  \n",
       "\n",
       "[304 rows x 32 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lucky Star 1</th>\n",
       "      <th>Lucky Star 2</th>\n",
       "      <th>Ball 1</th>\n",
       "      <th>Ball 2</th>\n",
       "      <th>Ball 3</th>\n",
       "      <th>Ball 4</th>\n",
       "      <th>Ball 5</th>\n",
       "      <th>Ball Delta</th>\n",
       "      <th>Ball Y Delta</th>\n",
       "      <th>LS Delta</th>\n",
       "      <th>...</th>\n",
       "      <th>Lucky Star 1 Repeat Last 10</th>\n",
       "      <th>Lucky Star 2 Repeat Last 10</th>\n",
       "      <th>Ball 1 Repeat Last 20</th>\n",
       "      <th>Ball 2 Repeat Last 20</th>\n",
       "      <th>Ball 3 Repeat Last 20</th>\n",
       "      <th>Ball 4 Repeat Last 20</th>\n",
       "      <th>Ball 5 Repeat Last 20</th>\n",
       "      <th>Lucky Star 1 Repeat Last 20</th>\n",
       "      <th>Lucky Star 2 Repeat Last 20</th>\n",
       "      <th>Ball Y Delta 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>42</td>\n",
       "      <td>4.555217</td>\n",
       "      <td>2.383275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.383275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "      <td>41</td>\n",
       "      <td>47</td>\n",
       "      <td>3.913119</td>\n",
       "      <td>5.126402</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.126402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>4.974937</td>\n",
       "      <td>3.768289</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.768289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>26</td>\n",
       "      <td>28</td>\n",
       "      <td>33</td>\n",
       "      <td>1.903943</td>\n",
       "      <td>2.986637</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.986637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>33</td>\n",
       "      <td>45</td>\n",
       "      <td>4.366062</td>\n",
       "      <td>5.803447</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.803447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>36</td>\n",
       "      <td>38</td>\n",
       "      <td>49</td>\n",
       "      <td>6.791539</td>\n",
       "      <td>2.814249</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.814249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>29</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "      <td>4.918079</td>\n",
       "      <td>3.143247</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.143247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>47</td>\n",
       "      <td>6.169481</td>\n",
       "      <td>3.831449</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.831449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>304 rows × 32 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- 1. Data Preparation ---\n",
    "\n",
    "def create_sequences(data, seq_length, pred_cols):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:(i + seq_length)].values\n",
    "        y = data.iloc[i + seq_length, :pred_cols].values\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# --- 2. Load and Preprocess Data ---\n",
    "\n",
    "# Example DataFrame creation\n",
    "num_rows = 2000\n",
    "num_cols = 32\n",
    "random_seed = np.random.rand(num_rows, num_cols)\n",
    "\n",
    "# Parameters\n",
    "seq_length = 7  # Number of past rows to look at\n",
    "pred_cols = 7  # Number of columns to predict\n",
    "all_cols = 32\n",
    "random_seed_length = 7 # Length of random seed\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df[::-1]), columns=df.columns)\n",
    "\n",
    "# Create sequences\n",
    "X, y = create_sequences(df, seq_length, pred_cols)\n",
    "\n",
    "# Split into training, validation, and test sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "# Input for the sequence\n",
    "sequence_input = tf.keras.layers.Input(shape=(seq_length, all_cols))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T01:46:44.175911Z",
     "start_time": "2025-01-12T01:46:43.628410Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T01:46:45.656348Z",
     "start_time": "2025-01-12T01:46:45.651308Z"
    }
   },
   "cell_type": "code",
   "source": "scaler.inverse_transform(X[-1])",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.00000000e+00,  7.00000000e+00,  1.00000000e+00,\n",
       "         3.00000000e+00,  4.00000000e+00,  2.10000000e+01,\n",
       "         2.90000000e+01,  4.73022198e+00,  7.66028720e+00,\n",
       "         5.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "         3.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         3.00000000e+00,  1.00000000e+00,  3.00000000e+00,\n",
       "        -2.22044605e-16,  3.00000000e+00,  3.00000000e+00,\n",
       "         2.00000000e+00,  7.66028720e+00],\n",
       "       [ 6.00000000e+00,  9.00000000e+00,  1.00000000e+01,\n",
       "         1.40000000e+01,  2.10000000e+01,  3.30000000e+01,\n",
       "         5.00000000e+01,  5.57897840e+00,  6.56048779e+00,\n",
       "         3.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "         2.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  3.00000000e+00,  3.00000000e+00,\n",
       "         2.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         2.00000000e+00,  4.00000000e+00,  4.00000000e+00,\n",
       "         6.00000000e+00,  6.56048779e+00],\n",
       "       [ 1.10000000e+01,  1.20000000e+01,  6.00000000e+00,\n",
       "         1.00000000e+01,  1.60000000e+01,  2.30000000e+01,\n",
       "         2.40000000e+01,  2.52487623e+00,  5.77234788e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         2.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "         2.22044605e-16,  3.00000000e+00,  0.00000000e+00,\n",
       "         2.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         4.00000000e+00,  5.77234788e+00],\n",
       "       [ 4.00000000e+00,  8.00000000e+00,  1.20000000e+01,\n",
       "         2.20000000e+01,  2.70000000e+01,  3.30000000e+01,\n",
       "         4.50000000e+01,  4.36606230e+00,  5.80344725e+00,\n",
       "         4.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "         1.11022302e-16,  1.00000000e+00,  2.00000000e+00,\n",
       "         2.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         3.00000000e+00,  2.00000000e+00,  1.00000000e+00,\n",
       "         3.00000000e+00,  5.80344725e+00],\n",
       "       [ 8.00000000e+00,  1.20000000e+01,  1.90000000e+01,\n",
       "         2.40000000e+01,  2.60000000e+01,  2.80000000e+01,\n",
       "         3.30000000e+01,  1.90394328e+00,  2.98663690e+00,\n",
       "         4.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "         2.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         2.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "         2.00000000e+00,  2.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  4.00000000e+00,  4.00000000e+00,\n",
       "         4.00000000e+00,  2.98663690e+00],\n",
       "       [ 1.00000000e+00,  9.00000000e+00,  3.00000000e+00,\n",
       "         1.90000000e+01,  2.90000000e+01,  3.50000000e+01,\n",
       "         3.70000000e+01,  4.97493719e+00,  3.76828874e+00,\n",
       "         8.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  1.00000000e+00,  1.00000000e+00,\n",
       "         1.00000000e+00,  3.00000000e+00,  0.00000000e+00,\n",
       "         1.11022302e-16,  2.22044605e-16,  3.00000000e+00,\n",
       "         1.00000000e+00,  3.00000000e+00,  4.00000000e+00,\n",
       "         1.00000000e+00,  1.00000000e+00,  2.00000000e+00,\n",
       "         6.00000000e+00,  3.76828874e+00],\n",
       "       [ 4.00000000e+00,  1.20000000e+01,  2.00000000e+01,\n",
       "         3.30000000e+01,  3.50000000e+01,  4.10000000e+01,\n",
       "         4.70000000e+01,  3.91311896e+00,  5.12640225e+00,\n",
       "         8.00000000e+00,  0.00000000e+00,  3.00000000e+00,\n",
       "         1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00000000e+00,  2.00000000e+00,  0.00000000e+00,\n",
       "         3.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "         3.00000000e+00,  2.00000000e+00,  2.00000000e+00,\n",
       "         1.00000000e+00,  5.00000000e+00,  2.00000000e+00,\n",
       "        -2.22044605e-16,  3.00000000e+00,  2.00000000e+00,\n",
       "         5.00000000e+00,  5.12640225e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T01:08:27.258172Z",
     "start_time": "2025-01-12T01:08:27.254943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# for testing sequences\n",
    "# df = df[::-1]\n",
    "# print(y[-1])\n",
    "# print(df.iloc[-1].values[:7])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6.  7. 12. 27. 36. 37. 42.]\n",
      "[ 6.  7. 12. 27. 36. 37. 42.]\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "source": [
    "# --- 3. Model Definition ---\n",
    "\n",
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # First 1D Convolutional layer\n",
    "    tf.keras.layers.Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(seq_length, all_cols)),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "\n",
    "    # LSTM layer\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "\n",
    "    # Reshape for Dense output\n",
    "    tf.keras.layers.Reshape((64, 2)),  # Reshape to add a time dimension\n",
    "\n",
    "    # Second 1D Convolutional layer\n",
    "    tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "\n",
    "    # Flatten for Dense output\n",
    "    tf.keras.layers.Flatten(),\n",
    "\n",
    "    # Output layer\n",
    "    tf.keras.layers.Dense(pred_cols),\n",
    "])\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-01-12T01:46:57.352271Z",
     "start_time": "2025-01-12T01:46:57.148638Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T01:47:06.239838Z",
     "start_time": "2025-01-12T01:47:06.228657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# --- 4. Loss Function with Emphasis ---\n",
    "\n",
    "def custom_loss(y_true, y_pred, random_target):\n",
    "    # Calculate loss\n",
    "    squared_error = tf.square(y_true - y_pred)\n",
    "    weighted_mse_loss = tf.reduce_mean(squared_error)\n",
    "\n",
    "    # MSE between prediction and random target\n",
    "    mse_loss_random = tf.reduce_mean(tf.square(y_pred - random_target))\n",
    "\n",
    "    # Combine the two losses (you can adjust the weights)\n",
    "    return 0.75 * weighted_mse_loss + 0.25 * mse_loss_random\n",
    "\n",
    "def generate_random_target(batch_size):\n",
    "    targets = []\n",
    "    for _ in range(batch_size):\n",
    "        first_two = np.random.randint(1, 13, size=2)\n",
    "        last_five = np.random.randint(1, 51, size=5)\n",
    "        target = np.concatenate([first_two, last_five])\n",
    "        targets.append(target)\n",
    "    return np.array(targets)\n",
    "\n",
    "# --- 5. Compile the Model ---\n",
    "\n",
    "lstm_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                   loss=custom_loss)  # Use the custom weighted loss\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T01:47:08.422691Z",
     "start_time": "2025-01-12T01:47:08.419038Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267, 7, 32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T01:48:24.759769Z",
     "start_time": "2025-01-12T01:47:52.407882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 6. Train the Model ---\n",
    "\n",
    "# Generate random seeds for training and validation data\n",
    "train_random_seeds = np.random.randint(1, 51, size=(X_train.shape[0], random_seed_length))\n",
    "val_random_seeds = np.random.randint(1, 51, size=(X_val.shape[0], random_seed_length))\n",
    "\n",
    "# Custom training loop\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 16\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for i in range(0, X_train.shape[0], batch_size):\n",
    "        # Get batch data\n",
    "\n",
    "        X_batch = X_train[i:(i + batch_size)]\n",
    "        y_batch = y_train[i:(i + batch_size)]\n",
    "        random_seeds_batch = generate_random_target(X_batch.shape[0])\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Get predictions\n",
    "            predictions = lstm_model([X_batch], training=True)\n",
    "\n",
    "            # Combine the two losses (you can adjust the weights)\n",
    "            loss = custom_loss(y_batch, predictions, random_seeds_batch)\n",
    "\n",
    "        # Compute and apply gradients\n",
    "        gradients = tape.gradient(loss, lstm_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, lstm_model.trainable_variables))\n",
    "\n",
    "        epoch_loss += loss\n",
    "\n",
    "    # Print epoch loss\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / (X_train.shape[0] // batch_size)}\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 131.0767364501953\n",
      "Epoch 2/200, Loss: 134.37245178222656\n",
      "Epoch 3/200, Loss: 134.67352294921875\n",
      "Epoch 4/200, Loss: 139.9173583984375\n",
      "Epoch 5/200, Loss: 138.18878173828125\n",
      "Epoch 6/200, Loss: 136.75778198242188\n",
      "Epoch 7/200, Loss: 132.17257690429688\n",
      "Epoch 8/200, Loss: 133.7996826171875\n",
      "Epoch 9/200, Loss: 135.7817840576172\n",
      "Epoch 10/200, Loss: 130.0947723388672\n",
      "Epoch 11/200, Loss: 134.62461853027344\n",
      "Epoch 12/200, Loss: 140.5101318359375\n",
      "Epoch 13/200, Loss: 138.22377014160156\n",
      "Epoch 14/200, Loss: 133.22413635253906\n",
      "Epoch 15/200, Loss: 136.03724670410156\n",
      "Epoch 16/200, Loss: 133.9053192138672\n",
      "Epoch 17/200, Loss: 133.4536895751953\n",
      "Epoch 18/200, Loss: 135.4148406982422\n",
      "Epoch 19/200, Loss: 135.10267639160156\n",
      "Epoch 20/200, Loss: 133.21820068359375\n",
      "Epoch 21/200, Loss: 130.6661376953125\n",
      "Epoch 22/200, Loss: 138.61148071289062\n",
      "Epoch 23/200, Loss: 139.01995849609375\n",
      "Epoch 24/200, Loss: 143.16989135742188\n",
      "Epoch 25/200, Loss: 135.34939575195312\n",
      "Epoch 26/200, Loss: 141.93634033203125\n",
      "Epoch 27/200, Loss: 137.07997131347656\n",
      "Epoch 28/200, Loss: 133.75628662109375\n",
      "Epoch 29/200, Loss: 136.61941528320312\n",
      "Epoch 30/200, Loss: 139.35353088378906\n",
      "Epoch 31/200, Loss: 138.8052215576172\n",
      "Epoch 32/200, Loss: 138.89031982421875\n",
      "Epoch 33/200, Loss: 139.85743713378906\n",
      "Epoch 34/200, Loss: 138.784423828125\n",
      "Epoch 35/200, Loss: 138.69300842285156\n",
      "Epoch 36/200, Loss: 135.58181762695312\n",
      "Epoch 37/200, Loss: 135.63592529296875\n",
      "Epoch 38/200, Loss: 136.69358825683594\n",
      "Epoch 39/200, Loss: 134.08290100097656\n",
      "Epoch 40/200, Loss: 140.3549346923828\n",
      "Epoch 41/200, Loss: 132.138427734375\n",
      "Epoch 42/200, Loss: 139.65452575683594\n",
      "Epoch 43/200, Loss: 136.14633178710938\n",
      "Epoch 44/200, Loss: 137.05319213867188\n",
      "Epoch 45/200, Loss: 139.1127471923828\n",
      "Epoch 46/200, Loss: 137.29898071289062\n",
      "Epoch 47/200, Loss: 136.7803192138672\n",
      "Epoch 48/200, Loss: 142.72837829589844\n",
      "Epoch 49/200, Loss: 137.8212127685547\n",
      "Epoch 50/200, Loss: 137.8483428955078\n",
      "Epoch 51/200, Loss: 134.49440002441406\n",
      "Epoch 52/200, Loss: 135.6229705810547\n",
      "Epoch 53/200, Loss: 140.1337127685547\n",
      "Epoch 54/200, Loss: 141.40325927734375\n",
      "Epoch 55/200, Loss: 137.29307556152344\n",
      "Epoch 56/200, Loss: 140.42491149902344\n",
      "Epoch 57/200, Loss: 134.54791259765625\n",
      "Epoch 58/200, Loss: 139.61248779296875\n",
      "Epoch 59/200, Loss: 140.55850219726562\n",
      "Epoch 60/200, Loss: 136.0096893310547\n",
      "Epoch 61/200, Loss: 133.33567810058594\n",
      "Epoch 62/200, Loss: 134.527587890625\n",
      "Epoch 63/200, Loss: 134.615478515625\n",
      "Epoch 64/200, Loss: 137.47332763671875\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_14416\\1630533158.py\u001B[0m in \u001B[0;36m?\u001B[1;34m()\u001B[0m\n\u001B[0;32m     26\u001B[0m             \u001B[1;31m# Combine the two losses (you can adjust the weights)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m             \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcustom_loss\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_batch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpredictions\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrandom_seeds_batch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     29\u001B[0m         \u001B[1;31m# Compute and apply gradients\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 30\u001B[1;33m         \u001B[0mgradients\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtape\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgradient\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlstm_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     31\u001B[0m         \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_gradients\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgradients\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlstm_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrainable_variables\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     32\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     33\u001B[0m         \u001B[0mepoch_loss\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\source\\lottery-counter\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001B[0m\n\u001B[0;32m   1061\u001B[0m               output_gradients))\n\u001B[0;32m   1062\u001B[0m       output_gradients = [None if x is None else ops.convert_to_tensor(x)\n\u001B[0;32m   1063\u001B[0m                           for x in output_gradients]\n\u001B[0;32m   1064\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1065\u001B[1;33m     flat_grad = imperative_grad.imperative_grad(\n\u001B[0m\u001B[0;32m   1066\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_tape\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1067\u001B[0m         \u001B[0mflat_targets\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1068\u001B[0m         \u001B[0mflat_sources\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\source\\lottery-counter\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001B[0m\n\u001B[0;32m     63\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     64\u001B[0m     raise ValueError(\n\u001B[0;32m     65\u001B[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001B[0;32m     66\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001B[0m\u001B[0;32m     68\u001B[0m       \u001B[0mtape\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_tape\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[1;31m# pylint: disable=protected-access\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m       \u001B[0mtarget\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     70\u001B[0m       \u001B[0msources\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\source\\lottery-counter\\venv\\Lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001B[0m\n\u001B[0;32m    143\u001B[0m     \u001B[0mgradient_name_scope\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"gradient_tape/\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    144\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mforward_pass_name_scope\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    145\u001B[0m       \u001B[0mgradient_name_scope\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[0mforward_pass_name_scope\u001B[0m \u001B[1;33m+\u001B[0m \u001B[1;34m\"/\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    146\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname_scope\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgradient_name_scope\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 147\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mgrad_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmock_op\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0mout_grads\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    148\u001B[0m   \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mgrad_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmock_op\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0mout_grads\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\source\\lottery-counter\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(op, grad)\u001B[0m\n\u001B[0;32m   1374\u001B[0m   \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mop\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1375\u001B[0m   if (isinstance(grad, tensor.Tensor) and\n\u001B[0;32m   1376\u001B[0m       \u001B[0m_ShapesFullySpecifiedAndEqual\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mand\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1377\u001B[0m       grad.dtype in (dtypes.int32, dtypes.float32)):\n\u001B[1;32m-> 1378\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0mgen_math_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmul\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgrad\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgen_math_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmul\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mgrad\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1379\u001B[0m   \u001B[1;32massert\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbase_dtype\u001B[0m \u001B[1;33m==\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbase_dtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\" vs. \"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1380\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1381\u001B[0m   (sx, rx, must_reduce_x), (sy, ry, must_reduce_y) = (\n",
      "\u001B[1;32m~\\source\\lottery-counter\\venv\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001B[0m in \u001B[0;36m?\u001B[1;34m(x, y, name)\u001B[0m\n\u001B[0;32m   7499\u001B[0m         _ctx, \"Mul\", name, x, y)\n\u001B[0;32m   7500\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   7501\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   7502\u001B[0m       \u001B[0m_ops\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraise_from_not_ok_status\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 7503\u001B[1;33m     \u001B[1;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_FallbackException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   7504\u001B[0m       \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   7505\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   7506\u001B[0m       return mul_eager_fallback(\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T01:48:27.279448Z",
     "start_time": "2025-01-12T01:48:27.241068Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 8. Evaluate the Model ---\n",
    "\n",
    "val_loss = 0\n",
    "for i in range(0, X_val.shape[0], batch_size):\n",
    "    X_batch = X_val[i:i + batch_size]\n",
    "    y_batch = y_val[i:i + batch_size]\n",
    "    random_target_batch = generate_random_target(X_batch.shape[0])\n",
    "\n",
    "    predictions = lstm_model([X_batch], training=False)\n",
    "    loss = custom_loss(y_batch, predictions, random_target_batch)\n",
    "    val_loss += loss\n",
    "\n",
    "print(f\"Validation Loss: {val_loss / (X_val.shape[0] / batch_size)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 135.19044494628906\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-12T01:48:29.301646Z",
     "start_time": "2025-01-12T01:48:29.258523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- 9. Make Predictions ---\n",
    "\n",
    "# Generate a random seed for prediction\n",
    "prediction_random_seed = np.random.randint(1, 51, size=(1, random_seed_length))\n",
    "\n",
    "# Get the last sequence from X_val and reshape it for prediction\n",
    "last_sequence = X[0].reshape(1, seq_length, all_cols)\n",
    "\n",
    "# Make a prediction using the last sequence and the random seed\n",
    "prediction = lstm_model.predict([last_sequence])\n",
    "\n",
    "# Inverse transform to get predictions in the original scale\n",
    "prediction = scaler.inverse_transform(np.concatenate((prediction, np.zeros((prediction.shape[0], all_cols - pred_cols))), axis=1))[:, :pred_cols]\n",
    "\n",
    "prediction"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 8.55346816, 12.34280668, 49.89598399, 63.60310763, 77.788169  ,\n",
       "        82.04879179, 83.22747375]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
