{
 "cells": [
  {
   "metadata": {},
   "cell_type": "raw",
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import tensorflow as tf\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import IPython\\n\",\n",
    "    \"import IPython.display\\n\",\n",
    "    \"import matplotlib as mpl\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Num GPUs Available: \\\", len(tf.config.list_physical_devices('GPU')))\\n\",\n",
    "    \"\\n\",\n",
    "    \"labels = [\\\"Lucky Star 1\\\", \\\"Lucky Star 2\\\", \\\"Ball 1\\\", \\\"Ball 2\\\", \\\"Ball 3\\\", \\\"Ball 4\\\", \\\"Ball 5\\\"]\\n\",\n",
    "    \"column_labels = [\\\"Lucky Star 1\\\", \\\"Lucky Star 2\\\", \\\"Ball 1\\\", \\\"Ball 2\\\", \\\"Ball 3\\\", \\\"Ball 4\\\", \\\"Ball 5\\\", \\\"Ball Delta\\\", \\\"Ball Y Delta\\\", \\\"LS Delta\\\",\\n\",\n",
    "    \"    \\\"Ball 1 Repeat Last 5\\\", \\\"Ball 2 Repeat Last 5\\\", \\\"Ball 3 Repeat Last 5\\\", \\\"Ball 4 Repeat Last 5\\\", \\\"Ball 5 Repeat Last 5\\\", \\\"Lucky Star 1 Repeat Last 5\\\", \\\"Lucky Star 2 Repeat Last 5\\\",\\n\",\n",
    "    \"    \\\"Ball 1 Repeat Last 10\\\", \\\"Ball 2 Repeat Last 10\\\", \\\"Ball 3 Repeat Last 10\\\", \\\"Ball 4 Repeat Last 10\\\", \\\"Ball 5 Repeat Last 10\\\", \\\"Lucky Star 1 Repeat Last 10\\\", \\\"Lucky Star 2 Repeat Last 10\\\",\\n\",\n",
    "    \"    \\\"Ball 1 Repeat Last 20\\\", \\\"Ball 2 Repeat Last 20\\\", \\\"Ball 3 Repeat Last 20\\\", \\\"Ball 4 Repeat Last 20\\\", \\\"Ball 5 Repeat Last 20\\\", \\\"Lucky Star 1 Repeat Last 20\\\", \\\"Lucky Star 2 Repeat Last 20\\\", \\\"Ball Y Delta 2\\\"\\n\",\n",
    "    \"]\\n\",\n",
    "    \"column_indices = {name: i for i, name in enumerate(column_labels)}\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-01-05T21:08:45.114903Z\",\n",
    "     \"start_time\": \"2025-01-05T21:08:45.110338Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Num GPUs Available:  0\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 47\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"df = pd.read_csv('euromillions-dataset.csv')\\n\",\n",
    "    \"df[\\\"Ball Y Delta 2\\\"] = df[\\\"Ball Y Delta\\\"]\\n\",\n",
    "    \"df\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-01-05T21:08:45.829503Z\",\n",
    "     \"start_time\": \"2025-01-05T21:08:45.817139Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"     Lucky Star 1  Lucky Star 2  Ball 1  Ball 2  Ball 3  Ball 4  Ball 5  \\\\\\n\",\n",
    "       \"0               1             9       3      19      29      35      37   \\n\",\n",
    "       \"1               8            12      19      24      26      28      33   \\n\",\n",
    "       \"2               4             8      12      22      27      33      45   \\n\",\n",
    "       \"3              11            12       6      10      16      23      24   \\n\",\n",
    "       \"4               6             9      10      14      21      33      50   \\n\",\n",
    "       \"..            ...           ...     ...     ...     ...     ...     ...   \\n\",\n",
    "       \"297             6             9       1      19      36      38      49   \\n\",\n",
    "       \"298             9            10      10      25      29      34      45   \\n\",\n",
    "       \"299             2             4       6      16      18      39      47   \\n\",\n",
    "       \"300             7            12       5      14      35      36      39   \\n\",\n",
    "       \"301             2             5       3      12      19      24      30   \\n\",\n",
    "       \"\\n\",\n",
    "       \"     Ball Delta  Ball Y Delta  LS Delta  ...  Lucky Star 1 Repeat Last 10  \\\\\\n\",\n",
    "       \"0      4.974937      3.768289         8  ...                            0   \\n\",\n",
    "       \"1      1.903943      2.986637         4  ...                            2   \\n\",\n",
    "       \"2      4.366062      5.803447         4  ...                            1   \\n\",\n",
    "       \"3      2.524876      5.772348         1  ...                            1   \\n\",\n",
    "       \"4      5.578978      6.560488         3  ...                            3   \\n\",\n",
    "       \"..          ...           ...       ...  ...                          ...   \\n\",\n",
    "       \"297    6.791539      2.814249         3  ...                            0   \\n\",\n",
    "       \"298    4.918079      3.143247         1  ...                            0   \\n\",\n",
    "       \"299    6.169481      3.831449         2  ...                            1   \\n\",\n",
    "       \"300    5.766281      4.422669         5  ...                            0   \\n\",\n",
    "       \"301    3.455069      8.921883         3  ...                            0   \\n\",\n",
    "       \"\\n\",\n",
    "       \"     Lucky Star 2 Repeat Last 10  Ball 1 Repeat Last 20  \\\\\\n\",\n",
    "       \"0                              3                      1   \\n\",\n",
    "       \"1                              2                      2   \\n\",\n",
    "       \"2                              2                      2   \\n\",\n",
    "       \"3                              2                      0   \\n\",\n",
    "       \"4                              3                      2   \\n\",\n",
    "       \"..                           ...                    ...   \\n\",\n",
    "       \"297                            1                      0   \\n\",\n",
    "       \"298                            0                      0   \\n\",\n",
    "       \"299                            0                      0   \\n\",\n",
    "       \"300                            0                      0   \\n\",\n",
    "       \"301                            0                      0   \\n\",\n",
    "       \"\\n\",\n",
    "       \"     Ball 2 Repeat Last 20  Ball 3 Repeat Last 20  Ball 4 Repeat Last 20  \\\\\\n\",\n",
    "       \"0                        3                      4                      1   \\n\",\n",
    "       \"1                        2                      0                      1   \\n\",\n",
    "       \"2                        1                      1                      3   \\n\",\n",
    "       \"3                        3                      0                      2   \\n\",\n",
    "       \"4                        1                      1                      2   \\n\",\n",
    "       \"..                     ...                    ...                    ...   \\n\",\n",
    "       \"297                      1                      1                      0   \\n\",\n",
    "       \"298                      0                      0                      0   \\n\",\n",
    "       \"299                      0                      0                      1   \\n\",\n",
    "       \"300                      0                      0                      0   \\n\",\n",
    "       \"301                      0                      0                      0   \\n\",\n",
    "       \"\\n\",\n",
    "       \"     Ball 5 Repeat Last 20  Lucky Star 1 Repeat Last 20  \\\\\\n\",\n",
    "       \"0                        1                            2   \\n\",\n",
    "       \"1                        4                            4   \\n\",\n",
    "       \"2                        2                            1   \\n\",\n",
    "       \"3                        1                            1   \\n\",\n",
    "       \"4                        4                            4   \\n\",\n",
    "       \"..                     ...                          ...   \\n\",\n",
    "       \"297                      0                            0   \\n\",\n",
    "       \"298                      0                            0   \\n\",\n",
    "       \"299                      0                            1   \\n\",\n",
    "       \"300                      0                            0   \\n\",\n",
    "       \"301                      0                            0   \\n\",\n",
    "       \"\\n\",\n",
    "       \"     Lucky Star 2 Repeat Last 20  Ball Y Delta 2  \\n\",\n",
    "       \"0                              6        3.768289  \\n\",\n",
    "       \"1                              4        2.986637  \\n\",\n",
    "       \"2                              3        5.803447  \\n\",\n",
    "       \"3                              4        5.772348  \\n\",\n",
    "       \"4                              6        6.560488  \\n\",\n",
    "       \"..                           ...             ...  \\n\",\n",
    "       \"297                            1        2.814249  \\n\",\n",
    "       \"298                            0        3.143247  \\n\",\n",
    "       \"299                            0        3.831449  \\n\",\n",
    "       \"300                            0        4.422669  \\n\",\n",
    "       \"301                            0        8.921883  \\n\",\n",
    "       \"\\n\",\n",
    "       \"[302 rows x 32 columns]\"\n",
    "      ],\n",
    "      \"text/html\": [\n",
    "       \"<div>\\n\",\n",
    "       \"<style scoped>\\n\",\n",
    "       \"    .dataframe tbody tr th:only-of-type {\\n\",\n",
    "       \"        vertical-align: middle;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe tbody tr th {\\n\",\n",
    "       \"        vertical-align: top;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"\\n\",\n",
    "       \"    .dataframe thead th {\\n\",\n",
    "       \"        text-align: right;\\n\",\n",
    "       \"    }\\n\",\n",
    "       \"</style>\\n\",\n",
    "       \"<table border=\\\"1\\\" class=\\\"dataframe\\\">\\n\",\n",
    "       \"  <thead>\\n\",\n",
    "       \"    <tr style=\\\"text-align: right;\\\">\\n\",\n",
    "       \"      <th></th>\\n\",\n",
    "       \"      <th>Lucky Star 1</th>\\n\",\n",
    "       \"      <th>Lucky Star 2</th>\\n\",\n",
    "       \"      <th>Ball 1</th>\\n\",\n",
    "       \"      <th>Ball 2</th>\\n\",\n",
    "       \"      <th>Ball 3</th>\\n\",\n",
    "       \"      <th>Ball 4</th>\\n\",\n",
    "       \"      <th>Ball 5</th>\\n\",\n",
    "       \"      <th>Ball Delta</th>\\n\",\n",
    "       \"      <th>Ball Y Delta</th>\\n\",\n",
    "       \"      <th>LS Delta</th>\\n\",\n",
    "       \"      <th>...</th>\\n\",\n",
    "       \"      <th>Lucky Star 1 Repeat Last 10</th>\\n\",\n",
    "       \"      <th>Lucky Star 2 Repeat Last 10</th>\\n\",\n",
    "       \"      <th>Ball 1 Repeat Last 20</th>\\n\",\n",
    "       \"      <th>Ball 2 Repeat Last 20</th>\\n\",\n",
    "       \"      <th>Ball 3 Repeat Last 20</th>\\n\",\n",
    "       \"      <th>Ball 4 Repeat Last 20</th>\\n\",\n",
    "       \"      <th>Ball 5 Repeat Last 20</th>\\n\",\n",
    "       \"      <th>Lucky Star 1 Repeat Last 20</th>\\n\",\n",
    "       \"      <th>Lucky Star 2 Repeat Last 20</th>\\n\",\n",
    "       \"      <th>Ball Y Delta 2</th>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </thead>\\n\",\n",
    "       \"  <tbody>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>0</th>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>9</td>\\n\",\n",
    "       \"      <td>3</td>\\n\",\n",
    "       \"      <td>19</td>\\n\",\n",
    "       \"      <td>29</td>\\n\",\n",
    "       \"      <td>35</td>\\n\",\n",
    "       \"      <td>37</td>\\n\",\n",
    "       \"      <td>4.974937</td>\\n\",\n",
    "       \"      <td>3.768289</td>\\n\",\n",
    "       \"      <td>8</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>3</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>3</td>\\n\",\n",
    "       \"      <td>4</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>6</td>\\n\",\n",
    "       \"      <td>3.768289</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>1</th>\\n\",\n",
    "       \"      <td>8</td>\\n\",\n",
    "       \"      <td>12</td>\\n\",\n",
    "       \"      <td>19</td>\\n\",\n",
    "       \"      <td>24</td>\\n\",\n",
    "       \"      <td>26</td>\\n\",\n",
    "       \"      <td>28</td>\\n\",\n",
    "       \"      <td>33</td>\\n\",\n",
    "       \"      <td>1.903943</td>\\n\",\n",
    "       \"      <td>2.986637</td>\\n\",\n",
    "       \"      <td>4</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>4</td>\\n\",\n",
    "       \"      <td>4</td>\\n\",\n",
    "       \"      <td>4</td>\\n\",\n",
    "       \"      <td>2.986637</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>2</th>\\n\",\n",
    "       \"      <td>4</td>\\n\",\n",
    "       \"      <td>8</td>\\n\",\n",
    "       \"      <td>12</td>\\n\",\n",
    "       \"      <td>22</td>\\n\",\n",
    "       \"      <td>27</td>\\n\",\n",
    "       \"      <td>33</td>\\n\",\n",
    "       \"      <td>45</td>\\n\",\n",
    "       \"      <td>4.366062</td>\\n\",\n",
    "       \"      <td>5.803447</td>\\n\",\n",
    "       \"      <td>4</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>3</td>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>3</td>\\n\",\n",
    "       \"      <td>5.803447</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>3</th>\\n\",\n",
    "       \"      <td>11</td>\\n\",\n",
    "       \"      <td>12</td>\\n\",\n",
    "       \"      <td>6</td>\\n\",\n",
    "       \"      <td>10</td>\\n\",\n",
    "       \"      <td>16</td>\\n\",\n",
    "       \"      <td>23</td>\\n\",\n",
    "       \"      <td>24</td>\\n\",\n",
    "       \"      <td>2.524876</td>\\n\",\n",
    "       \"      <td>5.772348</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>3</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>4</td>\\n\",\n",
    "       \"      <td>5.772348</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>4</th>\\n\",\n",
    "       \"      <td>6</td>\\n\",\n",
    "       \"      <td>9</td>\\n\",\n",
    "       \"      <td>10</td>\\n\",\n",
    "       \"      <td>14</td>\\n\",\n",
    "       \"      <td>21</td>\\n\",\n",
    "       \"      <td>33</td>\\n\",\n",
    "       \"      <td>50</td>\\n\",\n",
    "       \"      <td>5.578978</td>\\n\",\n",
    "       \"      <td>6.560488</td>\\n\",\n",
    "       \"      <td>3</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>3</td>\\n\",\n",
    "       \"      <td>3</td>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>4</td>\\n\",\n",
    "       \"      <td>4</td>\\n\",\n",
    "       \"      <td>6</td>\\n\",\n",
    "       \"      <td>6.560488</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>...</th>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>297</th>\\n\",\n",
    "       \"      <td>6</td>\\n\",\n",
    "       \"      <td>9</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>19</td>\\n\",\n",
    "       \"      <td>36</td>\\n\",\n",
    "       \"      <td>38</td>\\n\",\n",
    "       \"      <td>49</td>\\n\",\n",
    "       \"      <td>6.791539</td>\\n\",\n",
    "       \"      <td>2.814249</td>\\n\",\n",
    "       \"      <td>3</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>2.814249</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>298</th>\\n\",\n",
    "       \"      <td>9</td>\\n\",\n",
    "       \"      <td>10</td>\\n\",\n",
    "       \"      <td>10</td>\\n\",\n",
    "       \"      <td>25</td>\\n\",\n",
    "       \"      <td>29</td>\\n\",\n",
    "       \"      <td>34</td>\\n\",\n",
    "       \"      <td>45</td>\\n\",\n",
    "       \"      <td>4.918079</td>\\n\",\n",
    "       \"      <td>3.143247</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>3.143247</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>299</th>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>4</td>\\n\",\n",
    "       \"      <td>6</td>\\n\",\n",
    "       \"      <td>16</td>\\n\",\n",
    "       \"      <td>18</td>\\n\",\n",
    "       \"      <td>39</td>\\n\",\n",
    "       \"      <td>47</td>\\n\",\n",
    "       \"      <td>6.169481</td>\\n\",\n",
    "       \"      <td>3.831449</td>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>1</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>3.831449</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>300</th>\\n\",\n",
    "       \"      <td>7</td>\\n\",\n",
    "       \"      <td>12</td>\\n\",\n",
    "       \"      <td>5</td>\\n\",\n",
    "       \"      <td>14</td>\\n\",\n",
    "       \"      <td>35</td>\\n\",\n",
    "       \"      <td>36</td>\\n\",\n",
    "       \"      <td>39</td>\\n\",\n",
    "       \"      <td>5.766281</td>\\n\",\n",
    "       \"      <td>4.422669</td>\\n\",\n",
    "       \"      <td>5</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>4.422669</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"    <tr>\\n\",\n",
    "       \"      <th>301</th>\\n\",\n",
    "       \"      <td>2</td>\\n\",\n",
    "       \"      <td>5</td>\\n\",\n",
    "       \"      <td>3</td>\\n\",\n",
    "       \"      <td>12</td>\\n\",\n",
    "       \"      <td>19</td>\\n\",\n",
    "       \"      <td>24</td>\\n\",\n",
    "       \"      <td>30</td>\\n\",\n",
    "       \"      <td>3.455069</td>\\n\",\n",
    "       \"      <td>8.921883</td>\\n\",\n",
    "       \"      <td>3</td>\\n\",\n",
    "       \"      <td>...</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>0</td>\\n\",\n",
    "       \"      <td>8.921883</td>\\n\",\n",
    "       \"    </tr>\\n\",\n",
    "       \"  </tbody>\\n\",\n",
    "       \"</table>\\n\",\n",
    "       \"<p>302 rows Ã— 32 columns</p>\\n\",\n",
    "       \"</div>\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 48,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 48\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"n = len(df)\\n\",\n",
    "    \"train_df = df[0:int(n*0.7)]\\n\",\n",
    "    \"val_df = df[int(n*0.7):int(n*0.9)]\\n\",\n",
    "    \"test_df = df[int(n*0.9):]\\n\",\n",
    "    \"\\n\",\n",
    "    \"num_features = df.shape[1]\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-01-05T21:08:51.829366Z\",\n",
    "     \"start_time\": \"2025-01-05T21:08:51.825372Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 49\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"train_mean = train_df.mean()\\n\",\n",
    "    \"train_std = train_df.std()\\n\",\n",
    "    \"\\n\",\n",
    "    \"train_df = (train_df - train_mean) / train_std\\n\",\n",
    "    \"val_df = (val_df - train_mean) / train_std\\n\",\n",
    "    \"test_df = (test_df - train_mean) / train_std\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-01-05T21:08:52.469405Z\",\n",
    "     \"start_time\": \"2025-01-05T21:08:52.462085Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 50\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"class WindowGenerator():\\n\",\n",
    "    \"  def __init__(self, input_width, label_width, shift,\\n\",\n",
    "    \"               train_df=train_df, val_df=val_df, test_df=test_df,\\n\",\n",
    "    \"               label_columns=None):\\n\",\n",
    "    \"    # Store the raw data.\\n\",\n",
    "    \"    self.train_df = train_df\\n\",\n",
    "    \"    self.val_df = val_df\\n\",\n",
    "    \"    self.test_df = test_df\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Work out the label column indices.\\n\",\n",
    "    \"    self.label_columns = label_columns\\n\",\n",
    "    \"    if label_columns is not None:\\n\",\n",
    "    \"      self.label_columns_indices = {name: i for i, name in\\n\",\n",
    "    \"                                    enumerate(label_columns)}\\n\",\n",
    "    \"    self.column_indices = {name: i for i, name in\\n\",\n",
    "    \"                           enumerate(train_df.columns)}\\n\",\n",
    "    \"\\n\",\n",
    "    \"    # Work out the window parameters.\\n\",\n",
    "    \"    self.input_width = input_width\\n\",\n",
    "    \"    self.label_width = label_width\\n\",\n",
    "    \"    self.shift = shift\\n\",\n",
    "    \"\\n\",\n",
    "    \"    self.total_window_size = input_width + shift\\n\",\n",
    "    \"\\n\",\n",
    "    \"    self.input_slice = slice(0, input_width)\\n\",\n",
    "    \"    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\\n\",\n",
    "    \"\\n\",\n",
    "    \"    self.label_start = self.total_window_size - self.label_width\\n\",\n",
    "    \"    self.labels_slice = slice(self.label_start, None)\\n\",\n",
    "    \"    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\\n\",\n",
    "    \"\\n\",\n",
    "    \"  def __repr__(self):\\n\",\n",
    "    \"    return '\\\\n'.join([\\n\",\n",
    "    \"        f'Total window size: {self.total_window_size}',\\n\",\n",
    "    \"        f'Input indices: {self.input_indices}',\\n\",\n",
    "    \"        f'Label indices: {self.label_indices}',\\n\",\n",
    "    \"        f'Label column name(s): {self.label_columns}'])\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-01-05T21:08:52.875858Z\",\n",
    "     \"start_time\": \"2025-01-05T21:08:52.871320Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 51\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"def split_window(self, features):\\n\",\n",
    "    \"  inputs = features[:, self.input_slice, :]\\n\",\n",
    "    \"  labels = features[:, self.labels_slice, :]\\n\",\n",
    "    \"  if self.label_columns is not None:\\n\",\n",
    "    \"    labels = tf.stack(\\n\",\n",
    "    \"        [labels[:, :, self.column_indices[name]] for name in self.label_columns],\\n\",\n",
    "    \"        axis=-1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"  # Slicing doesn't preserve static shape information, so set the shapes\\n\",\n",
    "    \"  # manually. This way the `tf.data.Datasets` are easier to inspect.\\n\",\n",
    "    \"  inputs.set_shape([None, self.input_width, None])\\n\",\n",
    "    \"  labels.set_shape([None, self.label_width, None])\\n\",\n",
    "    \"\\n\",\n",
    "    \"  return inputs, labels\\n\",\n",
    "    \"\\n\",\n",
    "    \"WindowGenerator.split_window = split_window\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-01-05T21:08:53.934633Z\",\n",
    "     \"start_time\": \"2025-01-05T21:08:53.931136Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 52\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"w2 = WindowGenerator(input_width=(7 * 4) + 4, label_width=1, shift=1,\\n\",\n",
    "    \"                     label_columns=column_labels)\\n\",\n",
    "    \"w2\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-01-05T21:21:08.659754Z\",\n",
    "     \"start_time\": \"2025-01-05T21:21:08.655525Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"Total window size: 33\\n\",\n",
    "       \"Input indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\\n\",\n",
    "       \" 24 25 26 27 28 29 30 31]\\n\",\n",
    "       \"Label indices: [32]\\n\",\n",
    "       \"Label column name(s): ['Lucky Star 1', 'Lucky Star 2', 'Ball 1', 'Ball 2', 'Ball 3', 'Ball 4', 'Ball 5', 'Ball Delta', 'Ball Y Delta', 'LS Delta', 'Ball 1 Repeat Last 5', 'Ball 2 Repeat Last 5', 'Ball 3 Repeat Last 5', 'Ball 4 Repeat Last 5', 'Ball 5 Repeat Last 5', 'Lucky Star 1 Repeat Last 5', 'Lucky Star 2 Repeat Last 5', 'Ball 1 Repeat Last 10', 'Ball 2 Repeat Last 10', 'Ball 3 Repeat Last 10', 'Ball 4 Repeat Last 10', 'Ball 5 Repeat Last 10', 'Lucky Star 1 Repeat Last 10', 'Lucky Star 2 Repeat Last 10', 'Ball 1 Repeat Last 20', 'Ball 2 Repeat Last 20', 'Ball 3 Repeat Last 20', 'Ball 4 Repeat Last 20', 'Ball 5 Repeat Last 20', 'Lucky Star 1 Repeat Last 20', 'Lucky Star 2 Repeat Last 20', 'Ball Y Delta 2']\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 81,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 81\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"# Stack three slices, the length of the total window.\\n\",\n",
    "    \"example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\\n\",\n",
    "    \"                           np.array(train_df[20:20+w2.total_window_size]),\\n\",\n",
    "    \"                           np.array(train_df[40:40+w2.total_window_size])])\\n\",\n",
    "    \"\\n\",\n",
    "    \"example_inputs, example_labels = w2.split_window(example_window)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print('All shapes are: (batch, time, features)')\\n\",\n",
    "    \"print(f'Window shape: {example_window.shape}')\\n\",\n",
    "    \"print(f'Inputs shape: {example_inputs.shape}')\\n\",\n",
    "    \"print(f'Labels shape: {example_labels.shape}')\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-01-05T21:19:50.189414Z\",\n",
    "     \"start_time\": \"2025-01-05T21:19:50.178513Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"All shapes are: (batch, time, features)\\n\",\n",
    "      \"Window shape: (3, 2, 32)\\n\",\n",
    "      \"Inputs shape: (3, 1, 32)\\n\",\n",
    "      \"Labels shape: (3, 1, 32)\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 72\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"def make_dataset(self, data):\\n\",\n",
    "    \"  data = np.array(data, dtype=np.float32)\\n\",\n",
    "    \"  ds = tf.keras.utils.timeseries_dataset_from_array(\\n\",\n",
    "    \"      data=data,\\n\",\n",
    "    \"      targets=None,\\n\",\n",
    "    \"      sequence_length=self.total_window_size,\\n\",\n",
    "    \"      sequence_stride=1,\\n\",\n",
    "    \"      shuffle=True,\\n\",\n",
    "    \"      batch_size=32,)\\n\",\n",
    "    \"\\n\",\n",
    "    \"  ds = ds.map(self.split_window)\\n\",\n",
    "    \"\\n\",\n",
    "    \"  return ds\\n\",\n",
    "    \"\\n\",\n",
    "    \"WindowGenerator.make_dataset = make_dataset\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-01-05T21:19:52.381101Z\",\n",
    "     \"start_time\": \"2025-01-05T21:19:52.378028Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 73\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"@property\\n\",\n",
    "    \"def train(self):\\n\",\n",
    "    \"  return self.make_dataset(self.train_df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"@property\\n\",\n",
    "    \"def val(self):\\n\",\n",
    "    \"  return self.make_dataset(self.val_df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"@property\\n\",\n",
    "    \"def test(self):\\n\",\n",
    "    \"  return self.make_dataset(self.test_df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"@property\\n\",\n",
    "    \"def example(self):\\n\",\n",
    "    \"  \\\"\\\"\\\"Get and cache an example batch of `inputs, labels` for plotting.\\\"\\\"\\\"\\n\",\n",
    "    \"  result = getattr(self, '_example', None)\\n\",\n",
    "    \"  if result is None:\\n\",\n",
    "    \"    # No example batch was found, so get one from the `.train` dataset\\n\",\n",
    "    \"    result = next(iter(self.train))\\n\",\n",
    "    \"    # And cache it for next time\\n\",\n",
    "    \"    self._example = result\\n\",\n",
    "    \"  return result\\n\",\n",
    "    \"\\n\",\n",
    "    \"WindowGenerator.train = train\\n\",\n",
    "    \"WindowGenerator.val = val\\n\",\n",
    "    \"WindowGenerator.test = test\\n\",\n",
    "    \"WindowGenerator.example = example\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-01-05T21:19:55.519093Z\",\n",
    "     \"start_time\": \"2025-01-05T21:19:55.515505Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 74\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"# Each element is an (inputs, label) pair.\\n\",\n",
    "    \"w2.train.element_spec\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-01-05T21:19:59.342797Z\",\n",
    "     \"start_time\": \"2025-01-05T21:19:59.275969Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"(TensorSpec(shape=(None, 1, 32), dtype=tf.float32, name=None),\\n\",\n",
    "       \" TensorSpec(shape=(None, 1, 32), dtype=tf.float32, name=None))\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 75,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 75\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"lstm_model = tf.keras.models.Sequential([\\n\",\n",
    "    \"    # Shape [batch, time, features] => [batch, time, lstm_units]\\n\",\n",
    "    \"    tf.keras.layers.LSTM(128, return_sequences=False, kernel_regularizer=tf.keras.regularizers.l2(0.01)),\\n\",\n",
    "    \"    # Shape => [batch, time, features]\\n\",\n",
    "    \"    tf.keras.layers.Dense(units=1)\\n\",\n",
    "    \"])\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-01-05T21:23:43.957344Z\",\n",
    "     \"start_time\": \"2025-01-05T21:23:43.950686Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 98\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"wide_window = WindowGenerator(\\n\",\n",
    "    \"    input_width=32, label_width=1, shift=1,\\n\",\n",
    "    \"    label_columns=column_labels)\\n\",\n",
    "    \"\\n\",\n",
    "    \"wide_window\\n\",\n",
    "    \"\\n\",\n",
    "    \"print('Input shape:', wide_window.example[0].shape)\\n\",\n",
    "    \"print('Output shape:', lstm_model(wide_window.example[0]).shape)\\n\",\n",
    "    \"print(wide_window.example[0])\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-01-05T21:23:45.076695Z\",\n",
    "     \"start_time\": \"2025-01-05T21:23:44.790375Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Input shape: (32, 32, 32)\\n\",\n",
    "      \"Output shape: (32, 1)\\n\",\n",
    "      \"tf.Tensor(\\n\",\n",
    "      \"[[[-0.1495925  -0.2526785   1.1266454  ...  0.3439627  -0.714894\\n\",\n",
    "      \"    2.6288211 ]\\n\",\n",
    "      \"  [ 0.21743098  0.12544324 -0.8012326  ...  0.92457175  0.78354275\\n\",\n",
    "      \"    0.64878774]\\n\",\n",
    "      \"  [ 1.685525    1.2598085  -0.8012326  ...  0.3439627  -1.2143729\\n\",\n",
    "      \"   -0.49226895]\\n\",\n",
    "      \"  ...\\n\",\n",
    "      \"  [ 1.3185015   0.88168675  1.7198386  ... -0.8172554  -0.714894\\n\",\n",
    "      \"   -1.2384336 ]\\n\",\n",
    "      \"  [ 0.21743098  0.503565    0.9783471  ... -0.23664634  0.28406385\\n\",\n",
    "      \"   -0.29339394]\\n\",\n",
    "      \"  [ 0.5844545  -0.6308003  -1.0978292  ...  2.08579     0.28406385\\n\",\n",
    "      \"    0.75872916]]\\n\",\n",
    "      \"\\n\",\n",
    "      \" [[-0.1495925  -0.6308003  -0.20803933 ... -0.8172554  -0.714894\\n\",\n",
    "      \"   -0.93160534]\\n\",\n",
    "      \"  [-0.516616   -0.2526785  -1.0978292  ...  0.3439627  -0.714894\\n\",\n",
    "      \"   -1.3892548 ]\\n\",\n",
    "      \"  [-0.88363945 -1.7651656  -0.8012326  ... -1.3978645  -0.714894\\n\",\n",
    "      \"   -0.3850398 ]\\n\",\n",
    "      \"  ...\\n\",\n",
    "      \"  [ 0.95147794 -0.2526785   0.3851539  ...  0.3439627  -0.714894\\n\",\n",
    "      \"   -1.4112669 ]\\n\",\n",
    "      \"  [-1.2506629  -0.6308003   0.8300488  ... -1.3978645  -0.21541508\\n\",\n",
    "      \"   -0.9986983 ]\\n\",\n",
    "      \"  [-0.88363945 -2.1432874   1.4232421  ...  2.6663988   0.28406385\\n\",\n",
    "      \"   -0.34123188]]\\n\",\n",
    "      \"\\n\",\n",
    "      \" [[ 2.0525484   1.2598085  -1.2461275  ...  0.3439627  -0.714894\\n\",\n",
    "      \"   -0.9872804 ]\\n\",\n",
    "      \"  [ 0.21743098 -1.0089221  -0.8012326  ... -0.23664634  1.2830217\\n\",\n",
    "      \"    0.27578747]\\n\",\n",
    "      \"  [ 1.3185015   0.88168675  1.7198386  ... -0.8172554  -0.714894\\n\",\n",
    "      \"   -1.2384336 ]\\n\",\n",
    "      \"  ...\\n\",\n",
    "      \"  [-1.2506629  -0.6308003   0.8300488  ... -0.8172554   0.28406385\\n\",\n",
    "      \"    1.250986  ]\\n\",\n",
    "      \"  [-0.88363945  0.88168675 -0.65293425 ... -0.23664634  0.28406385\\n\",\n",
    "      \"    1.6451583 ]\\n\",\n",
    "      \"  [-0.516616    0.12544324  1.2749437  ... -0.23664634 -0.714894\\n\",\n",
    "      \"    2.3191128 ]]\\n\",\n",
    "      \"\\n\",\n",
    "      \" ...\\n\",\n",
    "      \"\\n\",\n",
    "      \" [[-0.516616    1.2598085  -0.9495309  ...  0.92457175 -0.714894\\n\",\n",
    "      \"    1.7156318 ]\\n\",\n",
    "      \"  [-1.2506629   1.2598085  -0.9495309  ...  0.92457175 -1.2143729\\n\",\n",
    "      \"   -0.28346643]\\n\",\n",
    "      \"  [-1.2506629  -0.6308003  -1.0978292  ...  0.3439627   1.2830217\\n\",\n",
    "      \"    0.9352513 ]\\n\",\n",
    "      \"  ...\\n\",\n",
    "      \"  [-0.1495925   1.2598085   0.5334522  ... -0.23664634  2.2819796\\n\",\n",
    "      \"    0.6959201 ]\\n\",\n",
    "      \"  [-0.1495925  -0.6308003  -0.20803933 ... -0.8172554  -0.714894\\n\",\n",
    "      \"   -0.93160534]\\n\",\n",
    "      \"  [-0.516616   -0.2526785  -1.0978292  ...  0.3439627  -0.714894\\n\",\n",
    "      \"   -1.3892548 ]]\\n\",\n",
    "      \"\\n\",\n",
    "      \" [[ 0.21743098 -0.2526785  -1.2461275  ...  1.5051808  -1.2143729\\n\",\n",
    "      \"   -0.64191806]\\n\",\n",
    "      \"  [-1.2506629   0.503565    0.9783471  ... -0.23664634 -1.2143729\\n\",\n",
    "      \"    1.0908741 ]\\n\",\n",
    "      \"  [ 0.21743098 -1.0089221  -1.0978292  ...  0.92457175 -0.714894\\n\",\n",
    "      \"   -0.3540149 ]\\n\",\n",
    "      \"  ...\\n\",\n",
    "      \"  [-0.1495925   1.2598085  -0.50463593 ...  0.3439627   0.28406385\\n\",\n",
    "      \"   -1.2244996 ]\\n\",\n",
    "      \"  [-0.88363945  1.2598085   0.08855728 ...  0.92457175 -0.21541508\\n\",\n",
    "      \"   -1.0335628 ]\\n\",\n",
    "      \"  [ 0.21743098  0.12544324 -1.0978292  ...  0.3439627   1.7825006\\n\",\n",
    "      \"   -0.67532533]]\\n\",\n",
    "      \"\\n\",\n",
    "      \" [[ 0.21743098 -1.0089221  -1.0978292  ...  0.92457175 -0.714894\\n\",\n",
    "      \"   -0.3540149 ]\\n\",\n",
    "      \"  [ 1.685525    0.503565   -0.20803933 ...  0.92457175 -1.7138518\\n\",\n",
    "      \"   -0.46759927]\\n\",\n",
    "      \"  [-1.2506629  -2.1432874  -0.35633764 ... -0.23664634  0.28406385\\n\",\n",
    "      \"    0.16064401]\\n\",\n",
    "      \"  ...\\n\",\n",
    "      \"  [ 0.21743098  0.12544324 -1.0978292  ...  0.3439627   1.7825006\\n\",\n",
    "      \"   -0.67532533]\\n\",\n",
    "      \"  [ 1.685525    1.2598085  -0.50463593 ...  1.5051808  -0.714894\\n\",\n",
    "      \"   -0.63591546]\\n\",\n",
    "      \"  [-0.1495925  -0.2526785   1.1266454  ...  0.3439627  -0.714894\\n\",\n",
    "      \"    2.6288211 ]]], shape=(32, 32, 32), dtype=float32)\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 99\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"MAX_EPOCHS = 120\\n\",\n",
    "    \"\\n\",\n",
    "    \"def compile_and_fit(model, window, patience=2):\\n\",\n",
    "    \"  # early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\\n\",\n",
    "    \"  #                                                   patience=patience,\\n\",\n",
    "    \"  #                                                   mode='min')\\n\",\n",
    "    \"\\n\",\n",
    "    \"  model.compile(loss=tf.keras.losses.MeanSquaredError(),\\n\",\n",
    "    \"                optimizer=tf.keras.optimizers.Adam(),\\n\",\n",
    "    \"                metrics=[tf.keras.metrics.MeanAbsoluteError()])\\n\",\n",
    "    \"\\n\",\n",
    "    \"  history = model.fit(window.train, epochs=MAX_EPOCHS,\\n\",\n",
    "    \"                      validation_data=window.val)\\n\",\n",
    "    \"  return history\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-01-05T21:28:30.758638Z\",\n",
    "     \"start_time\": \"2025-01-05T21:28:30.755350Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [],\n",
    "   \"execution_count\": 110\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"history = compile_and_fit(lstm_model, wide_window)\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-01-05T21:28:52.757464Z\",\n",
    "     \"start_time\": \"2025-01-05T21:28:31.625238Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"Epoch 1/120\\n\",\n",
    "      \"6/6 [==============================] - 2s 71ms/step - loss: 1.0192 - mean_absolute_error: 0.8199 - val_loss: 0.9522 - val_mean_absolute_error: 0.7948\\n\",\n",
    "      \"Epoch 2/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0192 - mean_absolute_error: 0.8184 - val_loss: 0.9522 - val_mean_absolute_error: 0.7948\\n\",\n",
    "      \"Epoch 3/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0190 - mean_absolute_error: 0.8167 - val_loss: 0.9513 - val_mean_absolute_error: 0.7946\\n\",\n",
    "      \"Epoch 4/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0188 - mean_absolute_error: 0.8188 - val_loss: 0.9507 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 5/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0190 - mean_absolute_error: 0.8212 - val_loss: 0.9518 - val_mean_absolute_error: 0.7946\\n\",\n",
    "      \"Epoch 6/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0190 - mean_absolute_error: 0.8183 - val_loss: 0.9526 - val_mean_absolute_error: 0.7948\\n\",\n",
    "      \"Epoch 7/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0190 - mean_absolute_error: 0.8163 - val_loss: 0.9538 - val_mean_absolute_error: 0.7951\\n\",\n",
    "      \"Epoch 8/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0191 - mean_absolute_error: 0.8184 - val_loss: 0.9531 - val_mean_absolute_error: 0.7949\\n\",\n",
    "      \"Epoch 9/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0191 - mean_absolute_error: 0.8161 - val_loss: 0.9504 - val_mean_absolute_error: 0.7946\\n\",\n",
    "      \"Epoch 10/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0191 - mean_absolute_error: 0.8189 - val_loss: 0.9496 - val_mean_absolute_error: 0.7946\\n\",\n",
    "      \"Epoch 11/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0192 - mean_absolute_error: 0.8178 - val_loss: 0.9490 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 12/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0195 - mean_absolute_error: 0.8197 - val_loss: 0.9495 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 13/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0193 - mean_absolute_error: 0.8211 - val_loss: 0.9500 - val_mean_absolute_error: 0.7946\\n\",\n",
    "      \"Epoch 14/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0191 - mean_absolute_error: 0.8197 - val_loss: 0.9523 - val_mean_absolute_error: 0.7951\\n\",\n",
    "      \"Epoch 15/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0193 - mean_absolute_error: 0.8189 - val_loss: 0.9542 - val_mean_absolute_error: 0.7954\\n\",\n",
    "      \"Epoch 16/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0193 - mean_absolute_error: 0.8155 - val_loss: 0.9528 - val_mean_absolute_error: 0.7949\\n\",\n",
    "      \"Epoch 17/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0187 - mean_absolute_error: 0.8197 - val_loss: 0.9504 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 18/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0190 - mean_absolute_error: 0.8153 - val_loss: 0.9497 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 19/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0188 - mean_absolute_error: 0.8168 - val_loss: 0.9504 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 20/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0191 - mean_absolute_error: 0.8169 - val_loss: 0.9514 - val_mean_absolute_error: 0.7947\\n\",\n",
    "      \"Epoch 21/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0190 - mean_absolute_error: 0.8193 - val_loss: 0.9517 - val_mean_absolute_error: 0.7948\\n\",\n",
    "      \"Epoch 22/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0188 - mean_absolute_error: 0.8193 - val_loss: 0.9520 - val_mean_absolute_error: 0.7948\\n\",\n",
    "      \"Epoch 23/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0188 - mean_absolute_error: 0.8176 - val_loss: 0.9509 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 24/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0188 - mean_absolute_error: 0.8174 - val_loss: 0.9492 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 25/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0192 - mean_absolute_error: 0.8201 - val_loss: 0.9493 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 26/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0190 - mean_absolute_error: 0.8160 - val_loss: 0.9498 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 27/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0191 - mean_absolute_error: 0.8166 - val_loss: 0.9499 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 28/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0189 - mean_absolute_error: 0.8189 - val_loss: 0.9498 - val_mean_absolute_error: 0.7942\\n\",\n",
    "      \"Epoch 29/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0188 - mean_absolute_error: 0.8206 - val_loss: 0.9503 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 30/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0186 - mean_absolute_error: 0.8188 - val_loss: 0.9508 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 31/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 26ms/step - loss: 1.0190 - mean_absolute_error: 0.8211 - val_loss: 0.9514 - val_mean_absolute_error: 0.7946\\n\",\n",
    "      \"Epoch 32/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 25ms/step - loss: 1.0189 - mean_absolute_error: 0.8194 - val_loss: 0.9512 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 33/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0188 - mean_absolute_error: 0.8199 - val_loss: 0.9510 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 34/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0185 - mean_absolute_error: 0.8167 - val_loss: 0.9513 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 35/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0188 - mean_absolute_error: 0.8157 - val_loss: 0.9506 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 36/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0187 - mean_absolute_error: 0.8195 - val_loss: 0.9500 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 37/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 25ms/step - loss: 1.0189 - mean_absolute_error: 0.8177 - val_loss: 0.9501 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 38/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0189 - mean_absolute_error: 0.8169 - val_loss: 0.9510 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 39/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0187 - mean_absolute_error: 0.8185 - val_loss: 0.9510 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 40/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0189 - mean_absolute_error: 0.8173 - val_loss: 0.9509 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 41/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0188 - mean_absolute_error: 0.8174 - val_loss: 0.9519 - val_mean_absolute_error: 0.7947\\n\",\n",
    "      \"Epoch 42/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 25ms/step - loss: 1.0187 - mean_absolute_error: 0.8163 - val_loss: 0.9521 - val_mean_absolute_error: 0.7947\\n\",\n",
    "      \"Epoch 43/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0187 - mean_absolute_error: 0.8163 - val_loss: 0.9524 - val_mean_absolute_error: 0.7948\\n\",\n",
    "      \"Epoch 44/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0190 - mean_absolute_error: 0.8192 - val_loss: 0.9514 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 45/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0188 - mean_absolute_error: 0.8173 - val_loss: 0.9500 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 46/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0187 - mean_absolute_error: 0.8183 - val_loss: 0.9496 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 47/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0188 - mean_absolute_error: 0.8186 - val_loss: 0.9499 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 48/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0188 - mean_absolute_error: 0.8172 - val_loss: 0.9509 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 49/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0188 - mean_absolute_error: 0.8155 - val_loss: 0.9510 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 50/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0187 - mean_absolute_error: 0.8181 - val_loss: 0.9508 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 51/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0185 - mean_absolute_error: 0.8186 - val_loss: 0.9505 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 52/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0192 - mean_absolute_error: 0.8183 - val_loss: 0.9499 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 53/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0188 - mean_absolute_error: 0.8149 - val_loss: 0.9507 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 54/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0192 - mean_absolute_error: 0.8190 - val_loss: 0.9513 - val_mean_absolute_error: 0.7948\\n\",\n",
    "      \"Epoch 55/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0195 - mean_absolute_error: 0.8190 - val_loss: 0.9501 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 56/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0191 - mean_absolute_error: 0.8179 - val_loss: 0.9501 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 57/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0191 - mean_absolute_error: 0.8185 - val_loss: 0.9510 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 58/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 25ms/step - loss: 1.0187 - mean_absolute_error: 0.8165 - val_loss: 0.9517 - val_mean_absolute_error: 0.7946\\n\",\n",
    "      \"Epoch 59/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0188 - mean_absolute_error: 0.8180 - val_loss: 0.9499 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 60/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0190 - mean_absolute_error: 0.8181 - val_loss: 0.9491 - val_mean_absolute_error: 0.7942\\n\",\n",
    "      \"Epoch 61/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0189 - mean_absolute_error: 0.8171 - val_loss: 0.9495 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 62/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0188 - mean_absolute_error: 0.8153 - val_loss: 0.9503 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 63/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0190 - mean_absolute_error: 0.8174 - val_loss: 0.9500 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 64/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 26ms/step - loss: 1.0188 - mean_absolute_error: 0.8193 - val_loss: 0.9494 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 65/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0187 - mean_absolute_error: 0.8187 - val_loss: 0.9494 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 66/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0186 - mean_absolute_error: 0.8164 - val_loss: 0.9503 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 67/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0190 - mean_absolute_error: 0.8194 - val_loss: 0.9507 - val_mean_absolute_error: 0.7946\\n\",\n",
    "      \"Epoch 68/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0189 - mean_absolute_error: 0.8170 - val_loss: 0.9503 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 69/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0188 - mean_absolute_error: 0.8158 - val_loss: 0.9502 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 70/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0187 - mean_absolute_error: 0.8181 - val_loss: 0.9499 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 71/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0188 - mean_absolute_error: 0.8188 - val_loss: 0.9498 - val_mean_absolute_error: 0.7942\\n\",\n",
    "      \"Epoch 72/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0189 - mean_absolute_error: 0.8193 - val_loss: 0.9500 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 73/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0187 - mean_absolute_error: 0.8193 - val_loss: 0.9508 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 74/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0185 - mean_absolute_error: 0.8186 - val_loss: 0.9515 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 75/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0189 - mean_absolute_error: 0.8170 - val_loss: 0.9510 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 76/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0187 - mean_absolute_error: 0.8176 - val_loss: 0.9506 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 77/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0187 - mean_absolute_error: 0.8187 - val_loss: 0.9504 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 78/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0189 - mean_absolute_error: 0.8186 - val_loss: 0.9504 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 79/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0186 - mean_absolute_error: 0.8182 - val_loss: 0.9497 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 80/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 25ms/step - loss: 1.0188 - mean_absolute_error: 0.8162 - val_loss: 0.9495 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 81/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0188 - mean_absolute_error: 0.8168 - val_loss: 0.9494 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 82/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0188 - mean_absolute_error: 0.8167 - val_loss: 0.9501 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 83/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0184 - mean_absolute_error: 0.8168 - val_loss: 0.9512 - val_mean_absolute_error: 0.7946\\n\",\n",
    "      \"Epoch 84/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0186 - mean_absolute_error: 0.8164 - val_loss: 0.9513 - val_mean_absolute_error: 0.7947\\n\",\n",
    "      \"Epoch 85/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0189 - mean_absolute_error: 0.8172 - val_loss: 0.9501 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 86/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0189 - mean_absolute_error: 0.8216 - val_loss: 0.9495 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 87/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0189 - mean_absolute_error: 0.8184 - val_loss: 0.9499 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 88/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 25ms/step - loss: 1.0187 - mean_absolute_error: 0.8185 - val_loss: 0.9505 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 89/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0187 - mean_absolute_error: 0.8184 - val_loss: 0.9510 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 90/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0188 - mean_absolute_error: 0.8155 - val_loss: 0.9512 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 91/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0188 - mean_absolute_error: 0.8173 - val_loss: 0.9508 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 92/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0188 - mean_absolute_error: 0.8203 - val_loss: 0.9500 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 93/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0190 - mean_absolute_error: 0.8170 - val_loss: 0.9500 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 94/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0187 - mean_absolute_error: 0.8161 - val_loss: 0.9500 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 95/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0187 - mean_absolute_error: 0.8180 - val_loss: 0.9496 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 96/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0187 - mean_absolute_error: 0.8172 - val_loss: 0.9497 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 97/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0187 - mean_absolute_error: 0.8190 - val_loss: 0.9498 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 98/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 21ms/step - loss: 1.0187 - mean_absolute_error: 0.8183 - val_loss: 0.9505 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 99/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0190 - mean_absolute_error: 0.8194 - val_loss: 0.9503 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 100/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0189 - mean_absolute_error: 0.8196 - val_loss: 0.9505 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 101/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0188 - mean_absolute_error: 0.8183 - val_loss: 0.9506 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 102/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0188 - mean_absolute_error: 0.8212 - val_loss: 0.9501 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 103/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 25ms/step - loss: 1.0187 - mean_absolute_error: 0.8189 - val_loss: 0.9501 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 104/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0188 - mean_absolute_error: 0.8164 - val_loss: 0.9503 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 105/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0189 - mean_absolute_error: 0.8184 - val_loss: 0.9504 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 106/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0187 - mean_absolute_error: 0.8175 - val_loss: 0.9507 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 107/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0187 - mean_absolute_error: 0.8203 - val_loss: 0.9516 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 108/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 23ms/step - loss: 1.0187 - mean_absolute_error: 0.8178 - val_loss: 0.9515 - val_mean_absolute_error: 0.7946\\n\",\n",
    "      \"Epoch 109/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0187 - mean_absolute_error: 0.8182 - val_loss: 0.9513 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 110/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 24ms/step - loss: 1.0187 - mean_absolute_error: 0.8180 - val_loss: 0.9507 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 111/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 21ms/step - loss: 1.0189 - mean_absolute_error: 0.8184 - val_loss: 0.9504 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 112/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0188 - mean_absolute_error: 0.8153 - val_loss: 0.9503 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 113/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0188 - mean_absolute_error: 0.8204 - val_loss: 0.9507 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 114/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0186 - mean_absolute_error: 0.8185 - val_loss: 0.9507 - val_mean_absolute_error: 0.7943\\n\",\n",
    "      \"Epoch 115/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0187 - mean_absolute_error: 0.8165 - val_loss: 0.9512 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 116/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0190 - mean_absolute_error: 0.8174 - val_loss: 0.9509 - val_mean_absolute_error: 0.7945\\n\",\n",
    "      \"Epoch 117/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0192 - mean_absolute_error: 0.8175 - val_loss: 0.9504 - val_mean_absolute_error: 0.7944\\n\",\n",
    "      \"Epoch 118/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0188 - mean_absolute_error: 0.8187 - val_loss: 0.9490 - val_mean_absolute_error: 0.7942\\n\",\n",
    "      \"Epoch 119/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0190 - mean_absolute_error: 0.8194 - val_loss: 0.9488 - val_mean_absolute_error: 0.7942\\n\",\n",
    "      \"Epoch 120/120\\n\",\n",
    "      \"6/6 [==============================] - 0s 22ms/step - loss: 1.0188 - mean_absolute_error: 0.8178 - val_loss: 0.9490 - val_mean_absolute_error: 0.7942\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 111\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"sample = tf.constant([[[i for i in j] for j in ((df[:4] - train_mean) / train_std).to_numpy()]])\\n\",\n",
    "    \"print(sample)\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-01-05T21:32:27.907798Z\",\n",
    "     \"start_time\": \"2025-01-05T21:32:27.902041Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"tf.Tensor(\\n\",\n",
    "      \"[[[-1.25066296  0.12544324 -0.94953088  0.27402476  0.3999915\\n\",\n",
    "      \"    0.08915825 -0.87284273 -0.1252147  -0.42453734  1.36642655\\n\",\n",
    "      \"    0.95202658  0.79652438  0.53706461 -0.73560218 -0.74170044\\n\",\n",
    "      \"   -1.07229149  0.18039108  0.14208047  0.04408188  1.87497328\\n\",\n",
    "      \"   -1.06920031 -1.07951767 -1.51156007  0.94008534 -0.69634595\\n\",\n",
    "      \"    0.65317385  1.36116957 -0.74573192 -0.7688341  -0.81725538\\n\",\n",
    "      \"    1.28302169 -0.42453734]\\n\",\n",
    "      \"  [ 1.31850142  1.25980854  1.42324206  0.90662022  0.07073972\\n\",\n",
    "      \"   -0.73906021 -1.46407809 -2.38475191 -0.81638992 -0.09525153\\n\",\n",
    "      \"   -0.69451119  0.79652438 -0.78061717 -0.73560218  2.26789174\\n\",\n",
    "      \"    0.2059769   0.18039108 -1.05707871  1.07755717 -1.13735689\\n\",\n",
    "      \"   -1.06920031  1.18693236  0.27022303  0.21349924  0.14807356\\n\",\n",
    "      \"   -0.04641845 -1.52533072 -0.74573192  1.58223829  0.3439627\\n\",\n",
    "      \"    0.28406384 -0.81638992]\\n\",\n",
    "      \"  [-0.14959251 -0.25267853  0.3851539   0.65358204  0.18049031\\n\",\n",
    "      \"   -0.1474756   0.309628   -0.57320499  0.59571499 -0.09525153\\n\",\n",
    "      \"   -0.69451119 -0.6649247  -0.78061717  0.78608469 -0.74170044\\n\",\n",
    "      \"    0.2059769  -0.87690107  0.14208047 -0.9893934  -1.13735689\\n\",\n",
    "      \"   -0.01498879 -1.07951767 -0.62066852  0.21349924  0.14807356\\n\",\n",
    "      \"   -0.74601075 -0.80370565  0.76724342  0.0148567  -1.39786443\\n\",\n",
    "      \"   -0.21541508  0.59571499]\\n\",\n",
    "      \"  [ 2.41957187  1.25980854 -0.50463595 -0.86464706 -1.02676621\\n\",\n",
    "      \"   -1.33064482 -2.79435766 -1.92788968  0.58012446 -1.19151009\\n\",\n",
    "      \"   -0.69451119  0.79652438 -0.78061717 -0.73560218  0.76309565\\n\",\n",
    "      \"   -1.07229149 -0.87690107 -1.05707871  1.07755717 -1.13735689\\n\",\n",
    "      \"   -0.01498879  0.05370735 -0.62066852  0.21349924 -1.54076547\\n\",\n",
    "      \"    0.65317385 -1.52533072  0.01075575 -0.7688341  -1.39786443\\n\",\n",
    "      \"    0.28406384  0.58012446]]], shape=(1, 4, 32), dtype=float64)\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 122\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"prediction = lstm_model.predict(sample)\\n\",\n",
    "    \"(prediction * tf.constant([train_std])) + tf.constant([train_mean])\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-01-05T21:33:26.787165Z\",\n",
    "     \"start_time\": \"2025-01-05T21:33:26.724032Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"ename\": \"ValueError\",\n",
    "     \"evalue\": \"in user code:\\n\\n    File \\\"C:\\\\Users\\\\ardav\\\\source\\\\lottery-counter\\\\venv\\\\Lib\\\\site-packages\\\\keras\\\\src\\\\engine\\\\training.py\\\", line 2416, in predict_function  *\\n        return step_function(self, iterator)\\n    File \\\"C:\\\\Users\\\\ardav\\\\source\\\\lottery-counter\\\\venv\\\\Lib\\\\site-packages\\\\keras\\\\src\\\\engine\\\\training.py\\\", line 2401, in step_function  **\\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\\n    File \\\"C:\\\\Users\\\\ardav\\\\source\\\\lottery-counter\\\\venv\\\\Lib\\\\site-packages\\\\keras\\\\src\\\\engine\\\\training.py\\\", line 2389, in run_step  **\\n        outputs = model.predict_step(data)\\n    File \\\"C:\\\\Users\\\\ardav\\\\source\\\\lottery-counter\\\\venv\\\\Lib\\\\site-packages\\\\keras\\\\src\\\\engine\\\\training.py\\\", line 2357, in predict_step\\n        return self(x, training=False)\\n    File \\\"C:\\\\Users\\\\ardav\\\\source\\\\lottery-counter\\\\venv\\\\Lib\\\\site-packages\\\\keras\\\\src\\\\utils\\\\traceback_utils.py\\\", line 70, in error_handler\\n        raise e.with_traceback(filtered_tb) from None\\n\\n    ValueError: Exception encountered when calling layer 'sequential_14' (type Sequential).\\n    \\n    Cannot iterate over a shape with unknown rank.\\n    \\n    Call arguments received by layer 'sequential_14' (type Sequential):\\n      â€¢ inputs=tf.Tensor(shape=<unknown>, dtype=float64)\\n      â€¢ training=False\\n      â€¢ mask=None\\n\",\n",
    "     \"output_type\": \"error\",\n",
    "     \"traceback\": [\n",
    "      \"\\u001B[1;31m---------------------------------------------------------------------------\\u001B[0m\",\n",
    "      \"\\u001B[1;31mValueError\\u001B[0m                                Traceback (most recent call last)\",\n",
    "      \"Cell \\u001B[1;32mIn[124], line 1\\u001B[0m\\n\\u001B[1;32m----> 1\\u001B[0m prediction \\u001B[38;5;241m=\\u001B[39m \\u001B[43mlstm_model\\u001B[49m\\u001B[38;5;241;43m.\\u001B[39;49m\\u001B[43mpredict\\u001B[49m\\u001B[43m(\\u001B[49m\\u001B[43mdf\\u001B[49m\\u001B[43m[\\u001B[49m\\u001B[43m:\\u001B[49m\\u001B[38;5;241;43m4\\u001B[39;49m\\u001B[43m]\\u001B[49m\\u001B[43m)\\u001B[49m\\n\\u001B[0;32m      2\\u001B[0m (prediction \\u001B[38;5;241m*\\u001B[39m tf\\u001B[38;5;241m.\\u001B[39mconstant([train_std])) \\u001B[38;5;241m+\\u001B[39m tf\\u001B[38;5;241m.\\u001B[39mconstant([train_mean])\\n\",\n",
    "      \"File \\u001B[1;32m~\\\\source\\\\lottery-counter\\\\venv\\\\Lib\\\\site-packages\\\\keras\\\\src\\\\utils\\\\traceback_utils.py:70\\u001B[0m, in \\u001B[0;36mfilter_traceback.<locals>.error_handler\\u001B[1;34m(*args, **kwargs)\\u001B[0m\\n\\u001B[0;32m     67\\u001B[0m     filtered_tb \\u001B[38;5;241m=\\u001B[39m _process_traceback_frames(e\\u001B[38;5;241m.\\u001B[39m__traceback__)\\n\\u001B[0;32m     68\\u001B[0m     \\u001B[38;5;66;03m# To get the full stack trace, call:\\u001B[39;00m\\n\\u001B[0;32m     69\\u001B[0m     \\u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\\u001B[39;00m\\n\\u001B[1;32m---> 70\\u001B[0m     \\u001B[38;5;28;01mraise\\u001B[39;00m e\\u001B[38;5;241m.\\u001B[39mwith_traceback(filtered_tb) \\u001B[38;5;28;01mfrom\\u001B[39;00m \\u001B[38;5;28;01mNone\\u001B[39;00m\\n\\u001B[0;32m     71\\u001B[0m \\u001B[38;5;28;01mfinally\\u001B[39;00m:\\n\\u001B[0;32m     72\\u001B[0m     \\u001B[38;5;28;01mdel\\u001B[39;00m filtered_tb\\n\",\n",
    "      \"File \\u001B[1;32m~\\\\AppData\\\\Local\\\\Temp\\\\__autograph_generated_file7vw1uqzd.py:15\\u001B[0m, in \\u001B[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\\u001B[1;34m(iterator)\\u001B[0m\\n\\u001B[0;32m     13\\u001B[0m \\u001B[38;5;28;01mtry\\u001B[39;00m:\\n\\u001B[0;32m     14\\u001B[0m     do_return \\u001B[38;5;241m=\\u001B[39m \\u001B[38;5;28;01mTrue\\u001B[39;00m\\n\\u001B[1;32m---> 15\\u001B[0m     retval_ \\u001B[38;5;241m=\\u001B[39m ag__\\u001B[38;5;241m.\\u001B[39mconverted_call(ag__\\u001B[38;5;241m.\\u001B[39mld(step_function), (ag__\\u001B[38;5;241m.\\u001B[39mld(\\u001B[38;5;28mself\\u001B[39m), ag__\\u001B[38;5;241m.\\u001B[39mld(iterator)), \\u001B[38;5;28;01mNone\\u001B[39;00m, fscope)\\n\\u001B[0;32m     16\\u001B[0m \\u001B[38;5;28;01mexcept\\u001B[39;00m:\\n\\u001B[0;32m     17\\u001B[0m     do_return \\u001B[38;5;241m=\\u001B[39m \\u001B[38;5;28;01mFalse\\u001B[39;00m\\n\",\n",
    "      \"\\u001B[1;31mValueError\\u001B[0m: in user code:\\n\\n    File \\\"C:\\\\Users\\\\ardav\\\\source\\\\lottery-counter\\\\venv\\\\Lib\\\\site-packages\\\\keras\\\\src\\\\engine\\\\training.py\\\", line 2416, in predict_function  *\\n        return step_function(self, iterator)\\n    File \\\"C:\\\\Users\\\\ardav\\\\source\\\\lottery-counter\\\\venv\\\\Lib\\\\site-packages\\\\keras\\\\src\\\\engine\\\\training.py\\\", line 2401, in step_function  **\\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\\n    File \\\"C:\\\\Users\\\\ardav\\\\source\\\\lottery-counter\\\\venv\\\\Lib\\\\site-packages\\\\keras\\\\src\\\\engine\\\\training.py\\\", line 2389, in run_step  **\\n        outputs = model.predict_step(data)\\n    File \\\"C:\\\\Users\\\\ardav\\\\source\\\\lottery-counter\\\\venv\\\\Lib\\\\site-packages\\\\keras\\\\src\\\\engine\\\\training.py\\\", line 2357, in predict_step\\n        return self(x, training=False)\\n    File \\\"C:\\\\Users\\\\ardav\\\\source\\\\lottery-counter\\\\venv\\\\Lib\\\\site-packages\\\\keras\\\\src\\\\utils\\\\traceback_utils.py\\\", line 70, in error_handler\\n        raise e.with_traceback(filtered_tb) from None\\n\\n    ValueError: Exception encountered when calling layer 'sequential_14' (type Sequential).\\n    \\n    Cannot iterate over a shape with unknown rank.\\n    \\n    Call arguments received by layer 'sequential_14' (type Sequential):\\n      â€¢ inputs=tf.Tensor(shape=<unknown>, dtype=float64)\\n      â€¢ training=False\\n      â€¢ mask=None\\n\"\n",
    "     ]\n",
    "    }\n",
    "   ],\n",
    "   \"execution_count\": 124\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"source\": [\n",
    "    \"sample = tf.constant([[[i for i in j] for j in (df[:4]).to_numpy()]])\\n\",\n",
    "    \"prediction = lstm_model.predict(sample)\\n\",\n",
    "    \"prediction\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2025-01-05T21:34:36.301401Z\",\n",
    "     \"start_time\": \"2025-01-05T21:34:36.262474Z\"\n",
    "    }\n",
    "   },\n",
    "   \"outputs\": [\n",
    "    {\n",
    "     \"name\": \"stdout\",\n",
    "     \"output_type\": \"stream\",\n",
    "     \"text\": [\n",
    "      \"1/1 [==============================] - 0s 11ms/step\\n\"\n",
    "     ]\n",
    "    },\n",
    "    {\n",
    "     \"data\": {\n",
    "      \"text/plain\": [\n",
    "       \"array([[-0.01918655]], dtype=float32)\"\n",
    "      ]\n",
    "     },\n",
    "     \"execution_count\": 129,\n",
    "     \"metadata\": {},\n",
    "     \"output_type\": \"execute_result\"\n",
    "    }\n",
    "   ],\n",
    "   \"source\": [\n",
    "    \"prediction = lstm_model.predict(sample)\\n\",\n",
    "    \"(prediction * tf.constant([train_std])) + tf.constant([train_mean])\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false,\n",
    "    \"ExecuteTime\": {\n",
    "     \"end_time\": \"2023-09-30T22:30:54.252143100Z\",\n",
    "     \"start_time\": \"2023-09-30T22:30:54.008764Z\"\n",
    "    }\n",
    "   }\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"source\": [\n",
    "    \"As seen above, and since the data set is very small, it is very probable for the network to fit using average values for each ball slot. One way around this problem is to add the difference between each ball and its surrounding value to the network inputs. This way there is more weight given to the ball values with respect to each other rather than just the average value of each ball slot.\\n\",\n",
    "    \"\\n\",\n",
    "    \"Another way to reduce this effect is to augment the data by, for example adding a constant value to each ball slot and repeating this to generate more data which carry the same trends in the data but not necessarily repeat the same ball values.\\n\",\n",
    "    \"\\n\",\n",
    "    \"A more natural way is to use a GAN to generate more data that have resemblance or closeness to the trends we see in the data. This way the essence of the trends is captured in the network rather than using some constant value to add to each data point.\"\n",
    "   ],\n",
    "   \"metadata\": {\n",
    "    \"collapsed\": false\n",
    "   }\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 2\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython2\",\n",
    "   \"version\": \"2.7.6\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 0\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
